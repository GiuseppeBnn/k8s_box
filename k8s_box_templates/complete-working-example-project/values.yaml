#nfsIp: 192.168.1.1 # This is the IP address of the NFS server, change it to the IP address of your NFS server
rootDirectory: /SharedFS # This is the root directory where all the files that need be searched and mounted are present

components:
  - name: replay
    image: python:latest
    commands: 
    - command: pip install -r /app/requirements.txt
    - command: cd /app/
    - command: python F1SessionReplayProducer.py
    
    volumes:
    - name: volume1
      directory: /app/
      mountPath: /app/

    active: true
  
  - name: logstash
    image: logstash:8.7.1
    ports:
    - protocol: TCP
      port: 5000
    - protocol: TCP
      port: 5001
    - protocol: TCP
      port: 5002

    environment:
    - name: LS_JAVA_OPTS
      value: -Xms1g -Xmx1g

    volumes:
    - name: logstash-config-pipelines-confs
      directory: /pipeline/confs
      mountPath: /usr/share/logstash/pipeline/
    - name: logstash-pipelinesyml
      file: /pipeline/pipelines.yml
      mountPath: /usr/share/logstash/config/pipelines.yml

    active: true
  
  - name: zookeeper
    image: confluentinc/cp-zookeeper:latest
    ports:
    - protocol: TCP
      port: 2181
    environment:
    - name: ZOOKEEPER_CLIENT_PORT
      value: 2181
    - name: ZOOKEEPER_TICK_TIME
      value: 2000
    
    active: true

  - name: broker
    image: "confluentinc/cp-kafka:latest"
    ports:
    - port: 29093
      protocol: TCP
    - port: 29094
      protocol: TCP
    - port: 29095
      protocol: TCP
    - port: 9092
      protocol: TCP
    environment:
    - name: KAFKA_BROKER_ID
      value: 1
    - name: KAFKA_ZOOKEEPER_CONNECT
      value: zookeeper:2181
    - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
      value: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT,KAFKA_UI:PLAINTEXT,SPARK:PLAINTEXT
    - name: KAFKA_ADVERTISED_LISTENERS
      value: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092,PLAINTEXT_EXTERNAL://broker:29093,KAFKA_UI://broker:29094,SPARK://broker:29095
    - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
      value: 1
    - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
      value: 1
    - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
      value: 1
    jobs:
      image: confluentinc/cp-kafka:latest
      commands: 
      - command: kafka-topics --bootstrap-server broker:29093 --list 
      - command: kafka-topics --bootstrap-server broker:29093 --create --if-not-exists --topic LiveTimingData
  
    active: true

  - name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
    - port: 8080
      protocol: TCP
      hostPort: 30000
    environment:
    - name: KAFKA_CLUSTERS_0_NAME
      value: "F1"
    - name: KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS
      value: "broker:29095"
    - name: KAFKA_CLUSTERS_0_ZOOKEEPER
      value: "zookeeper:2181"
    active: true

  - name: sp-master
    image: bde2020/spark-master:3.3.0-hadoop3.3
    ports:
    - port: 8090
      protocol: TCP
    - port: 7077
      protocol: TCP
    environment:
    - name: INIT_DAEMON_STEP
      value: "setup_spark"
    - name: SPARK_MASTER_WEBUI_PORT
      value: "8090"
    - name: SPARK_WORKLOAD
      value: "master"
    - name: SPARK_DRIVER_MEMORY
      value: "2g"
    active: true

  - name: sp-worker
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    replicas: 2
    ports:
    - port: 8081
      protocol: TCP
    environment:
    - name: SPARK_MASTER
      value: spark://sp-master:7077
    - name: SPARK_WORKER_CORES
      value: "1"
    - name: SPARK_WORKER_MEMORY
      value: "2g"
    - name: SPARK_WORKER_WEBUI_PORT
      value: "8081"
    - name: SPARK_EXECUTOR_MEMORY
      value: "2g"
    - name: SPARK_WORKLOAD
      value: "worker"
    active: true

  - name: pyspark
    image: jupyter/pyspark-notebook:python-3.7.12
    ports:
    - port: 4040
      protocol: TCP
    - port: 9999
      protocol: TCP
    - port: 9191
      protocol: TCP
    volumes:
    - name: pyspark
      file: /SparkRegression.py
      mountPath: /home/jovyan/SparkRegression.py
    commands:
    - command: pip install elasticsearch
    - command: echo "Starting PySpark Job"
    - command: spark-submit --conf spark.blockManager.port=9191 --conf spark.driver.port=9999 --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 --master spark://sp-master:7077 /home/jovyan/SparkRegression.py
    active: true

  - name: elasticsearch
    image: elasticsearch:8.7.1
    ports:
    - port: 9200
      protocol: TCP
    environment:
    - name: discovery.type
      value: single-node
    - name: xpack.security.enabled
      value: "false"
    - name: ES_JAVA_OPTS
      value: "-Xms1g -Xmx1g"
    active: true
  
  - name: kibana
    image: kibana:8.7.1
    ports:
    - port: 5601
      protocol: TCP
      hostPort: 30001
    environment:
    - name: ELASTICSEARCH_HOSTS
      value: http://elasticsearch:9200
    active: true